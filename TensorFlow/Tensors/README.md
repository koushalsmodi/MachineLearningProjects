# Universal machine learning workflow

## Collecting a dataset

## Building a model

## Deploying a model
--**Weight Pruning**: keep significant weights only to reduce model size and improve inference speed.
--**Weight Quantization**: convert weights from 'float32' to 'int8' to reduce memory usage and accelerate computations.