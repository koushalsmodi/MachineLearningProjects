{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YG1PnfHL8SW1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mnist_model():\n",
        "  inputs = keras.Input(shape= (28*28,))\n",
        "  features = layers.Dense(512, activation = \"relu\")(inputs)\n",
        "  features = layers.Dropout(0.5)(features)\n",
        "  outputs = layers.Dense(10, activation = \"softmax\")(features)\n",
        "  model = keras.Model(inputs, outputs)\n",
        "  return model"
      ],
      "metadata": {
        "id": "zxDnjOoE8ot6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(images, labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "metadata": {
        "id": "X2AFp5CJ8p1L"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = images.reshape((60000, 28*28)).astype(\"float32\")/255\n",
        "test_images = test_images.reshape((10000, 28*28)).astype(\"float32\")/255\n",
        "train_images, val_images = images[10000:], images[:10000]\n",
        "train_labels, val_labels = labels[10000:], labels[:10000]"
      ],
      "metadata": {
        "id": "hSSRHHMa8qy6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_mnist_model()\n",
        "\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = keras.optimizers.RMSprop()\n",
        "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
        "loss_tracking_metric = keras.metrics.Mean()"
      ],
      "metadata": {
        "id": "9twNlqOg8r10"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def training_step(inputs, targets):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(inputs, training = True)\n",
        "    loss = loss_fn(targets, predictions)\n",
        "  gradients = tape.gradient(loss, model.trainable_weights)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "\n",
        "  logs = {}\n",
        "  for metric in metrics:\n",
        "    # accumulating metrics across batches\n",
        "    metric.update_state(targets, predictions)\n",
        "    logs[metric.name] = metric.result()\n",
        "\n",
        "  # accumulating the mean of the loss values across batches\n",
        "  loss_tracking_metric.update_state(loss)\n",
        "  logs[\"loss\"] = loss_tracking_metric.result()\n",
        "  return logs\n",
        "\n",
        "def reset_metrics():\n",
        "  for metric in metrics:\n",
        "    metric.reset_state()\n",
        "  # A single object\n",
        "  loss_tracking_metric.reset_state()"
      ],
      "metadata": {
        "id": "zylIdNEC86mG"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "training_dataset = training_dataset.batch(32)\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  reset_metrics()\n",
        "  for inputs_batch, targets_batch in training_dataset:\n",
        "    logs = training_step(inputs_batch, targets_batch)\n",
        "  print(f\"Results at the end of epoch {epoch}\")\n",
        "  for key, value in logs.items():\n",
        "    print(f\"...{key}: {value:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-F72avF_Cxs",
        "outputId": "07c78894-a3aa-441a-aaa7-3575ed94dba4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results at the end of epoch 0\n",
            "...sparse_categorical_accuracy: 0.9150\n",
            "...loss: 0.2864\n",
            "Results at the end of epoch 1\n",
            "...sparse_categorical_accuracy: 0.9548\n",
            "...loss: 0.1580\n",
            "Results at the end of epoch 2\n",
            "...sparse_categorical_accuracy: 0.9633\n",
            "...loss: 0.1324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation loop\n",
        "@tf.function\n",
        "def test_step(inputs, targets):\n",
        "  predictions = model(inputs, training = False)\n",
        "  loss = loss_fn(targets, predictions)\n",
        "\n",
        "  logs = {}\n",
        "  for metric in metrics:\n",
        "    metric.update_state(targets, predictions)\n",
        "    logs[\"val_\" + metric.name] = metric.result()\n",
        "\n",
        "  loss_tracking_metric.update_state(loss)\n",
        "  logs[\"val_loss\"] = loss_tracking_metric.result()\n",
        "  return logs\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
        "val_dataset = val_dataset.batch(32)\n",
        "reset_metrics()\n",
        "\n",
        "for inputs_batch, targets_batch in val_dataset:\n",
        "  logs = test_step(inputs_batch, targets_batch)\n",
        "print(\"Evaluation. results:\")\n",
        "for key, value in logs.items():\n",
        "  print(f\"...{key}: {value:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RObfyWCS7NZ",
        "outputId": "d02e2753-6290-46e6-f84a-86039ab63b70"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation. results:\n",
            "...val_sparse_categorical_accuracy: 0.9678\n",
            "...val_loss: 0.1251\n"
          ]
        }
      ]
    }
  ]
}