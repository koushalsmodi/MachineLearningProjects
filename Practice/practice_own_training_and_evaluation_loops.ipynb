{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "XSstdzjzSE1w"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "metadata": {
        "id": "8CIPi4Xdabk4"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yj_wsUXrfL8O",
        "outputId": "a161bb5c-e7aa-4d45-938f-08c45f9b9164"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset = tf.data.Dataset.from_tensor_slices((tf.reshape(train_images, [-1, 28*28]), train_labels))\n",
        "training_dataset = training_dataset.batch(32)"
      ],
      "metadata": {
        "id": "LSWk9ENOcFHi"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mnist_model():\n",
        "\n",
        "  inputs = keras.Input(shape = (28*28,))\n",
        "  features = layers.Dense(512, activation=\"relu\")(inputs)\n",
        "  features = layers.Dropout(0.5)(features)\n",
        "  outputs = layers.Dense(10, activation = \"softmax\")(features)\n",
        "  model = keras.Model(inputs, outputs)\n",
        "  return model"
      ],
      "metadata": {
        "id": "WLr4iwlyakmH"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_mnist_model()\n",
        "\n",
        "optimizer = keras.optimizers.RMSprop()\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
        "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
        "loss_tracking_metric = keras.metrics.Mean()\n",
        "\n",
        "def train_step(inputs, targets):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(inputs, training = True)\n",
        "    loss = loss_fn(targets, predictions)\n",
        "  gradients = tape.gradient(loss, model.trainable_weights)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "\n",
        "  logs = {}\n",
        "  for metric in metrics:\n",
        "    metric.update_state(targets, predictions)\n",
        "    logs[metric.name] = metric.result()\n",
        "\n",
        "  loss_tracking_metric.update_state(loss)\n",
        "  logs[\"loss\"] = loss_tracking_metric.result()\n",
        "  return logs"
      ],
      "metadata": {
        "id": "7NNONp0haoDK"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reset_metrics():\n",
        "  for metric in metrics:\n",
        "    metric.reset_state()\n",
        "  loss_tracking_metric.reset_state()"
      ],
      "metadata": {
        "id": "qg29oDVKb5Xh"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 3\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  reset_metrics()\n",
        "  for inputs_batch, targets_batch in training_dataset:\n",
        "    logs = train_step(inputs_batch, targets_batch)\n",
        "  print(f\"Results at the end of epoch: {epoch}\")\n",
        "  for key, value in logs.items():\n",
        "    print(f\"...{key}: {value:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3DTMfxJcyzQ",
        "outputId": "77699b2e-cc85-4f1a-8082-b80acea592b1"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results at the end of epoch: 0\n",
            "...sparse_categorical_accuracy: 0.8371\n",
            "...loss: 4.4400\n",
            "Results at the end of epoch: 1\n",
            "...sparse_categorical_accuracy: 0.8877\n",
            "...loss: 1.0226\n",
            "Results at the end of epoch: 2\n",
            "...sparse_categorical_accuracy: 0.9051\n",
            "...loss: 0.9037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step(inputs, targets):\n",
        "  predictions = model(inputs, training = False)\n",
        "  loss = loss_fn(targets, predictions)\n",
        "\n",
        "  logs = {}\n",
        "  for metric in metrics:\n",
        "    metric.update_state(targets, predictions)\n",
        "    logs[\"val\" + metric.name] = metric.result()\n",
        "\n",
        "  loss_tracking_metric.update_state(loss)\n",
        "  logs[\"loss\"] = loss_tracking_metric.result()\n",
        "\n",
        "  return logs\n",
        "\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((tf.reshape(test_images, [-1, 28*28]), tf.squeeze(test_labels))).batch(32)\n",
        "\n",
        "reset_metrics()\n",
        "\n",
        "for inputs_batch, targets_batch in test_dataset:\n",
        "  logs = test_step(inputs_batch, targets_batch)\n",
        "print(f\"Evaluation results:\")\n",
        "for key, value in logs.items():\n",
        "  print(f\"...{key}: {value:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZL-0RkKpdNZZ",
        "outputId": "6735c01c-d3f2-4ca1-f9f6-80a95f900726"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation results:\n",
            "...valsparse_categorical_accuracy: 0.9437\n",
            "...loss: 0.7116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make it faster by adding tf.function() by compiling eager code into Computation graph\n",
        "# Will loose out on debugging power, however!\n",
        "\n",
        "@tf.function\n",
        "def test_step(inputs, targets):\n",
        "  predictions = model(inputs, training = False)\n",
        "  loss = loss_fn(targets, predictions)\n",
        "\n",
        "  logs = {}\n",
        "  for metric in metrics:\n",
        "    metric.update_state(targets, predictions)\n",
        "    logs[\"val\" + metric.name] = metric.result()\n",
        "\n",
        "  loss_tracking_metric.update_state(loss)\n",
        "  logs[\"loss\"] = loss_tracking_metric.result()\n",
        "\n",
        "  return logs\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (tf.reshape(test_images, [-1, 28*28]), tf.squeeze(test_labels))\n",
        ").batch(32)\n",
        "\n",
        "reset_metrics()\n",
        "\n",
        "for inputs_batch, targets_batch in test_dataset:\n",
        "  logs = test_step(inputs_batch, targets_batch)\n",
        "print(f\"Evaluation results:\")\n",
        "for key, value in logs.items():\n",
        "  print(f\"...{key}: {value:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0VSZ1ydf-EF",
        "outputId": "49add4d6-8d07-44ab-c87c-0a6332ac8c12"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation results:\n",
            "...valsparse_categorical_accuracy: 0.9437\n",
            "...loss: 0.7116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Leveraging fit() with a custom training loop\n",
        "\n",
        "class CustomModel(keras.Model):\n",
        "  def train_step(self, data):\n",
        "    inputs, targets = data\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = self(inputs, training = True)\n",
        "      loss = self.compiled_loss(targets, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "    self.compiled_metrics.upadte_stae(targets, predictions)\n",
        "    return {m.name: m.result() for m in metrics}\n"
      ],
      "metadata": {
        "id": "eRONjZFghOZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(28, 28))\n",
        "x = layers.Flatten()(inputs)\n",
        "x = layers.Dense(512, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer = keras.optimizers.RMSprop(),\n",
        "              loss = keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics = [keras.metrics.SparseCategoricalAccuracy()])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs = 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0M1Gi02pzE-",
        "outputId": "2cde2823-50e1-4366-b1b3-6de618021e35"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 11.6266 - sparse_categorical_accuracy: 0.7935\n",
            "Epoch 2/3\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 1.0484 - sparse_categorical_accuracy: 0.8828\n",
            "Epoch 3/3\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.8693 - sparse_categorical_accuracy: 0.9047\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fee3bdeb410>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    }
  ]
}